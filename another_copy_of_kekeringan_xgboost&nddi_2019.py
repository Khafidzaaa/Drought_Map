# -*- coding: utf-8 -*-
"""Another copy of Kekeringan_XGBoost&NDDI_2019.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1i38_fx3539034cmqU5icpaw9MySigNlF

## Mendapatkan citra Sentinel-2 multitemporal bulanan dengan GEEMAP

Data citra yang akan digunakan adalah data citra Sentinel-2. Pada part ini kita akan mencoba mendapatkan data Sentinel-2 multitemporal bulanan pada bulan musim kemarau, yaitu antara bulan Juli, Agustus, dan September
Kita akan menggunakan library GEEMAP untuk mengakses Google Earth Engine API sehingga dapat menggunakan data yang tersedia pada database GEE.
"""

# Mounting Google Drive
from google.colab import drive
drive.mount('/content/drive')

## Import Library yang dibutuhkan
import ee
import geemap

# additional library
!pip install pycrs

# Melakukan autentikasi dan mendefinisikan Google Cloud Project yang akan digunakan
ee.Authenticate()
ee.Initialize(project='ee-khafidz') #ganti dengan nama Google Cloud Project anda

# Menambahkan basemap
m = geemap.Map()
m

# Memasukkan shapefile AOI dan mengubahnya kedalam earth engine object
AOI_ee = geemap.shp_to_ee("/content/drive/MyDrive/Bahan_Penelitian/Sawah Indramayu 2019/sawah_im_19_gcs.shp")
AOI_ee = AOI_ee.geometry()

# Menambahkan AOI Kedalam Peta GEEMAP
m.addLayer(AOI_ee, {}, "AOI IM")
m.centerObject(AOI_ee, 10) #Set zoom in
m

"""### Sentinel-2 dan Slope
* Setelah berhasil mengimport AOI, langkah selanjutnya adalah membuat function untuk mendapatkan data citra sentinel-2 setiap bulan pada bulan yang dikehendaki.
* Sebagai tambahan kita kan mendownload data slope dari SRTM pada part ini

"""

# def Combined_Monthly(start_month, end_month, year, AOI):
#     # Koleksi Citra Sentinel-2A dan Landsat-8
#     S2_Col = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')
#     L8_Col = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2')

#     # Add CHIRPS precipitation data
#     CHIRPS = ee.ImageCollection('UCSB-CHG/CHIRPS/DAILY')

#     # Cloud masking functions for Sentinel-2
#     def mask_s2_clouds(image):
#         qa = image.select('QA60')
#         cloud_bit_mask = 1 << 10
#         cirrus_bit_mask = 1 << 11
#         mask = qa.bitwiseAnd(cloud_bit_mask).eq(0).And(
#             qa.bitwiseAnd(cirrus_bit_mask).eq(0)
#         )
#         return image.updateMask(mask).divide(10000)

#     # Apply scaling factors for Landsat-8
#     def applyScaleFactors(image):
#         opticalBands = image.select('SR_B.').multiply(0.0000275).add(-0.2)
#         thermalBands = image.select('ST_B.*').multiply(0.00341802).add(149.0)
#         return image.addBands(opticalBands, None, True).addBands(thermalBands, None, True)

#     # Cloud masking function for Landsat-8
#     def L8cloudMask(image):
#         cloudShadowBitmask = (1 << 3)
#         cloudBitmask = (1 << 5)
#         qa = image.select('QA_PIXEL')
#         mask = qa.bitwiseAnd(cloudShadowBitmask).eq(0).And(qa.bitwiseAnd(cloudBitmask).eq(0))
#         return image.updateMask(mask)

#     # Menghitung NDVI untuk VCI calculation
#     def addNDVI(image):
#         ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI_temp')
#         return image.addBands(ndvi)

#     # Empty dictionary to store monthly data
#     monthly_data = {}

#     # Process data untuk setiap bulan
#     for month in range(start_month, end_month + 1):
#         start_date = f"{year}-{month:02d}-01"
#         end_date = f"{year}-{month + 1:02d}-01" if month < 12 else f"{year + 1}-01-01"

#         # Process Sentinel-2 data
#         S2_filtered = S2_Col.filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 25))\
#             .filter(ee.Filter.date(start_date, end_date))\
#             .filter(ee.Filter.bounds(AOI))\
#             .map(mask_s2_clouds)\
#             .select('B2', 'B3', 'B4', 'B8', 'B11', 'B12')

#         # Mendapatkan median composite
#         S2_medianComposite = S2_filtered.median().clip(AOI)

#         # Mendapatkan min and max NDVI dari koleksi untuk VCI calculation
#         ndviCollection = S2_filtered.map(addNDVI).select('NDVI_temp')
#         ndviMin = ndviCollection.min()
#         ndviMax = ndviCollection.max()
#         ndviMedian = addNDVI(S2_medianComposite).select('NDVI_temp')

#         # Process Landsat-8 data
#         L8_filtered = L8_Col.filter(ee.Filter.date(start_date, end_date))\
#             .filter(ee.Filter.bounds(AOI))\
#             .map(applyScaleFactors)\
#             .map(L8cloudMask)

#         # Create median composite and clip to area
#         L8_medianComposite = L8_filtered.median().clip(AOI)

#         # Calculate LST and TCI
#         L8_STB10 = L8_medianComposite.select('ST_B10')
#         L8_LST_Cel = L8_STB10.expression('STB10 - 273.15', {
#             'STB10': L8_STB10.select('ST_B10')
#         }).rename('LST')

#         # Calculate TCI
#         LSTmax = L8_LST_Cel.reduceRegion(
#             reducer=ee.Reducer.max(),
#             geometry=AOI,
#             scale=30
#         ).get('LST')
#         LSTmin = L8_LST_Cel.reduceRegion(
#             reducer=ee.Reducer.min(),
#             geometry=AOI,
#             scale=30
#         ).get('LST')

#         LSTmax_image = ee.Image.constant(LSTmax)
#         LSTmin_image = ee.Image.constant(LSTmin)

#         # Calculate TCI: (LSTmax - LST) / (LSTmax - LSTmin)
#         TCI = L8_LST_Cel.subtract(LSTmax_image)\
#             .divide(LSTmax_image.subtract(LSTmin_image))\
#             .rename('TCI')

#         # Process precipitation data
#         precipitation = CHIRPS.filter(ee.Filter.date(start_date, end_date))\
#             .filter(ee.Filter.bounds(AOI))\
#             .select('precipitation')\
#             .sum()\
#             .rename('Precipitation')\
#             .clip(AOI)

#         # Menghitung VCI (Vegetation Condition Index)
#         VCI = ndviMedian.subtract(ndviMin)\
#             .divide(ndviMax.subtract(ndviMin))\
#             .rename('VCI')

#         # Menghitung VHI (Vegetation Health Index)
#         VHI = VCI.multiply(0.5).add(TCI.multiply(0.5)).rename('VHI')

#         # Menambahkan elevation and slope data
#         dataset_SRTM = ee.Image('CGIAR/SRTM90_V4')
#         elevation = dataset_SRTM.select('elevation').clip(AOI)
#         slope = ee.Terrain.slope(elevation).rename('slope').clip(AOI)

#         # Menggabungkan semua bands
#         final_composite = S2_medianComposite\
#             .addBands(elevation)\
#             .addBands(slope)\
#             .addBands(L8_LST_Cel)\
#             .addBands(precipitation)\
#             .addBands(VCI)\
#             .addBands(TCI)\
#             .addBands(VHI)\
#             .float()

#         # Store monthly data
#         monthly_data[month] = final_composite

#     return monthly_data

def Combined_Monthly(start_month, end_month, year, AOI):
    # Koleksi Citra Sentinel-2A dan Landsat-8
    S2_Col = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')
    L8_Col = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2')

    # Add CHIRPS precipitation data
    CHIRPS = ee.ImageCollection('UCSB-CHG/CHIRPS/DAILY')

    # Cloud masking functions for Sentinel-2
    def mask_s2_clouds(image):
        qa = image.select('QA60')
        cloud_bit_mask = 1 << 10
        cirrus_bit_mask = 1 << 11
        mask = qa.bitwiseAnd(cloud_bit_mask).eq(0).And(
            qa.bitwiseAnd(cirrus_bit_mask).eq(0)
        )
        return image.updateMask(mask).divide(10000)

    # Apply scaling factors for Landsat-8
    def applyScaleFactors(image):
        opticalBands = image.select('SR_B.').multiply(0.0000275).add(-0.2)
        thermalBands = image.select('ST_B.*').multiply(0.00341802).add(149.0)
        return image.addBands(opticalBands, None, True).addBands(thermalBands, None, True)

    # Cloud masking function for Landsat-8
    def L8cloudMask(image):
        cloudShadowBitmask = (1 << 3)
        cloudBitmask = (1 << 5)
        qa = image.select('QA_PIXEL')
        mask = qa.bitwiseAnd(cloudShadowBitmask).eq(0).And(qa.bitwiseAnd(cloudBitmask).eq(0))
        return image.updateMask(mask)

    # Menghitung NDVI untuk VCI calculation
    def addNDVI(image):
        ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI_temp')
        return image.addBands(ndvi)

    # Fungsi baru untuk resampling dan penggabungan data
    def resample_and_combine(S2_composite, L8_LST, TCI, target_scale=10):
        # Melakukan resampling LST dan TCI ke resolusi Sentinel-2
        LST_resampled = L8_LST.reproject(
            crs=S2_composite.projection(),
            scale=target_scale
        )

        TCI_resampled = TCI.reproject(
            crs=S2_composite.projection(),
            scale=target_scale
        )

        return S2_composite\
            .addBands(LST_resampled)\
            .addBands(TCI_resampled)

    # Empty dictionary to store monthly data
    monthly_data = {}

    # Process data untuk setiap bulan
    for month in range(start_month, end_month + 1):
        try:
            start_date = f"{year}-{month:02d}-01"
            end_date = f"{year}-{month + 1:02d}-01" if month < 12 else f"{year + 1}-01-01"

            # Process Sentinel-2 data
            S2_filtered = S2_Col.filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 25))\
                .filter(ee.Filter.date(start_date, end_date))\
                .filter(ee.Filter.bounds(AOI))\
                .map(mask_s2_clouds)\
                .select('B2', 'B3', 'B4', 'B8', 'B11', 'B12')

            # Mendapatkan median composite
            S2_medianComposite = S2_filtered.median().clip(AOI)

            # Mendapatkan min and max NDVI dari koleksi untuk VCI calculation
            ndviCollection = S2_filtered.map(addNDVI).select('NDVI_temp')
            ndviMin = ndviCollection.min()
            ndviMax = ndviCollection.max()
            ndviMedian = addNDVI(S2_medianComposite).select('NDVI_temp')

            # Process Landsat-8 data
            L8_filtered = L8_Col.filter(ee.Filter.date(start_date, end_date))\
                .filter(ee.Filter.bounds(AOI))\
                .map(applyScaleFactors)\
                .map(L8cloudMask)

            # Periksa apakah ada data Landsat-8 yang tersedia
            if L8_filtered.size().getInfo() > 0:
                # Create median composite and clip to area
                L8_medianComposite = L8_filtered.median().clip(AOI)

                # Calculate LST and TCI
                L8_STB10 = L8_medianComposite.select('ST_B10')
                L8_LST_Cel = L8_STB10.expression('STB10 - 273.15', {
                    'STB10': L8_STB10.select('ST_B10')
                }).rename('LST')

                # Calculate TCI
                LSTmax = L8_LST_Cel.reduceRegion(
                    reducer=ee.Reducer.max(),
                    geometry=AOI,
                    scale=30
                ).get('LST')
                LSTmin = L8_LST_Cel.reduceRegion(
                    reducer=ee.Reducer.min(),
                    geometry=AOI,
                    scale=30
                ).get('LST')

                LSTmax_image = ee.Image.constant(LSTmax)
                LSTmin_image = ee.Image.constant(LSTmin)

                # Calculate TCI: (LSTmax - LST) / (LSTmax - LSTmin)
                TCI = L8_LST_Cel.subtract(LSTmax_image)\
                    .divide(LSTmax_image.subtract(LSTmin_image))\
                    .rename('TCI')
            else:
                print(f"Warning: No Landsat-8 data available for month {month}")
                L8_LST_Cel = ee.Image.constant(0).rename('LST')
                TCI = ee.Image.constant(0).rename('TCI')

            # Process precipitation data
            precipitation = CHIRPS.filter(ee.Filter.date(start_date, end_date))\
                .filter(ee.Filter.bounds(AOI))\
                .select('precipitation')\
                .sum()\
                .rename('Precipitation')\
                .clip(AOI)

            # Menghitung VCI (Vegetation Condition Index)
            VCI = ndviMedian.subtract(ndviMin)\
                .divide(ndviMax.subtract(ndviMin))\
                .rename('VCI')

            # Menghitung VHI (Vegetation Health Index)
            VHI = VCI.multiply(0.5).add(TCI.multiply(0.5)).rename('VHI')

            # Menambahkan elevation and slope data
            dataset_SRTM = ee.Image('CGIAR/SRTM90_V4')
            elevation = dataset_SRTM.select('elevation').clip(AOI)
            slope = ee.Terrain.slope(elevation).rename('slope').clip(AOI)

            # Gunakan fungsi resampling untuk LST dan TCI
            resampled_thermal = resample_and_combine(S2_medianComposite, L8_LST_Cel, TCI)

            # Menggabungkan semua bands
            final_composite = resampled_thermal\
                .addBands(elevation)\
                .addBands(slope)\
                .addBands(precipitation)\
                .addBands(VCI)\
                .addBands(VHI)\
                .float()

            # Store monthly data
            monthly_data[month] = final_composite

        except Exception as e:
            print(f"Error processing month {month}: {str(e)}")
            continue

    return monthly_data

# Menerapkan fungsi S2_monthly untuk mendapatkan data citra sentinel-2 bulanan
monthly_images = Combined_Monthly(start_month=7, end_month=10, year=2019, AOI=AOI_ee)

juli_image = monthly_images[7] # Extract data S2 bulan juli
# agustus_image = monthly_images[8] # Extract data S2 bulan Agustus
# september_image = monthly_images[9] # Extract data S2 bulan September
# oktober_image = monthly_images[10] # Extract data S2 bulan Oktober

juli_image

# Visualisasi citra Sentinel-2 setiap bulan
m.addLayer(juli_image, {'bands': ['B4', 'B3', 'B2'], 'min': 0, 'max': 0.3}, 'Juli Composite')
# m.addLayer(agustus_image, {'bands': ['B4', 'B3', 'B2'], 'min': 0, 'max': 0.3}, 'Agustus Composite')
# m.addLayer(september_image, {'bands': ['B4', 'B3', 'B2'], 'min': 0, 'max': 0.3}, 'September Composite')
# m.addLayer(oktober_image, {'bands': ['B4', 'B3', 'B2'], 'min': 0, 'max': 0.3}, 'Oktober Composite')
m

# Download S2 data setiap bulan ke Google Drive kita
# Export dengan default WGS84 tanpa mendefinisikan CRS
geemap.ee_export_image_to_drive(juli_image, description="S2_Juli_2019", folder="Data_Kekeringan_Final_2019", region=AOI_ee, scale=10)

geemap.ee_export_image_to_drive(agustus_image, description="S2_Agustus_2019", folder="Data_Kekeringan_Final_2019", region=AOI_ee, scale=10)

geemap.ee_export_image_to_drive(september_image, description="S2_September_2019", folder="Data_Kekeringan_Final_2019", region=AOI_ee, scale=10)

geemap.ee_export_image_to_drive(oktober_image, description="S2_Oktober_2019", folder="Data_Kekeringan_Final_2019", region=AOI_ee, scale=10)

"""Untuk melihat perkembangan export ke google drive. Kita bisa menggunakan Link:
https://code.earthengine.google.com/tasks

Setelah berhasil ke export, kita bisa mengunduh data.tif tersebut dan memakainya sesuai kebutuhan kita.

## Perhitungan indeks NDDI dan Reklasifikasi
Pada part ini kita akan belajar untuk membuat indeks NDDI dan sekaligus reklasifikasi kelas kekeringan indeks NDDI tersebut.
Kelas kekeringan ini akan digunakan sebagai target data.
"""

# install Library rasterio
!pip install rasterio

# Import Library yang dibutuhkan
import rasterio
import numpy as np
import matplotlib.pyplot as plt

# Memangggil data Sentinel-2 yang sudah dimasukkan kedalam google drive kita
S2_dataset_juli = rasterio.open('/content/drive/MyDrive/Bahan_Penelitian/Data_Kekeringan_Final_2019/S2_Juli_2019.tif')
S2_dataset_agustus = rasterio.open('/content/drive/MyDrive/Bahan_Penelitian/Data_Kekeringan_Final_2019/S2_Agustus_2019.tif')
S2_dataset_september = rasterio.open('/content/drive/MyDrive/Bahan_Penelitian/Data_Kekeringan_Final_2019/S2_September_2019.tif')
S2_dataset_oktober = rasterio.open('/content/drive/MyDrive/Bahan_Penelitian/Data_Kekeringan_Final_2019/S2_Oktober_2019.tif')

# untuk membuka semua band di data raster, kita bisa menggunakan
S2_juli_all = S2_dataset_juli.read()
S2_juli_all.shape

S2_agustus_all = S2_dataset_agustus.read()
S2_agustus_all.shape

S2_september_all = S2_dataset_september.read()
S2_september_all.shape

S2_oktober_all = S2_dataset_oktober.read()
S2_oktober_all.shape

# Bisa kita lihat, format shape dari data tersebut adalah bands, row, column
# Untuk Plot data raster dengan matplotlib, kita harus menggunakan format shape row, column,bands
# Ubah format shape menjadi row, column, bands:
S2_juli_all = S2_juli_all.transpose(1, 2, 0)
S2_juli_all.shape

S2_agustus_all = S2_agustus_all.transpose(1, 2, 0)
S2_agustus_all.shape

S2_september_all = S2_september_all.transpose(1, 2, 0)
S2_september_all.shape

S2_oktober_all = S2_oktober_all.transpose(1, 2, 0)
S2_oktober_all.shape

# Deskripsi list bands pada data
desc = S2_dataset_juli.descriptions

print('Raster description: {desc}\n'.format(desc=desc))

# Membuat function untuk menghitung indeks NDDI
# Indeks NDDI adalah normilzed ratio dari dua indeks yaitu NDVI dan NDWI.
# Oleh karena itu, terlebih dahulu kita perlu menghiyng NDVI dan NDWI sebelum melakukan perhitungan indeks NDDI

def NDDI_calculation(image):
  RED = image[:,:,2]
  NIR = image[:,:,3]
  SWIR1 = image[:,:,4]

  # NDVI Calculation
  NDVI = (NIR-RED)/(NIR+RED)

  # NDWI Calculation
  NDWI = (NIR-SWIR1)/(NIR+SWIR1)

  # NDDI Calculation
  NDDI = (NDVI-NDWI)/(NDVI+NDWI)
  return NDDI

# Menerpakan perhitungan Indeks NDDI
NDDI_juli = NDDI_calculation(S2_juli_all)
NDDI_agustus = NDDI_calculation(S2_agustus_all)
NDDI_september = NDDI_calculation(S2_september_all)
NDDI_oktober = NDDI_calculation(S2_oktober_all)
NDDI_juli.shape

# Visualisasi indeks NDDI

# List data NDDI dan judul
nddi_data = [NDDI_juli, NDDI_agustus, NDDI_september, NDDI_oktober]
titles = ['NDDI Bulan Juli', 'NDDI Bulan Agustus', 'NDDI Bulan September', 'NDDI Bulan Oktober']

# Batasan nilai minimum dan maksimum
vmin, vmax = -2, 5

# Loop untuk membuat plot
for i, data in enumerate(nddi_data):
    plt.figure(figsize=(6, 6))
    plt.imshow(data, cmap='viridis', vmin=vmin, vmax=vmax)
    plt.colorbar(label='NDDI', shrink=0.5)
    plt.title(titles[i])
    plt.axis('off')  # Matikan axis
    plt.tight_layout()
    plt.show()

# Menyimpan indeks NDDI
# Pertama kita harus mengupdate metadata berdasarkan data clipped raster
meta_nddi = S2_dataset_juli.meta.copy()
# Update metadata karena hanya memiliki satu band yang akan diexport
meta_nddi.update({"count": 1})
meta_nddi

# Export NDDI bulan juli
NDDI_export_path = '/content/drive/MyDrive/Bahan_Penelitian/Data_Kekeringan_Final_2019/Sentinel2_NDDI_Juli_2019.tif'

# Write the clipped raster to a new GeoTIFF file
with rasterio.open(NDDI_export_path, "w", **meta_nddi) as dst:
    dst.write(NDDI_juli, 1) # Pilih NDDI: , 1 menunjukan hanya export satu band
print("NDDI completed and saved as", NDDI_export_path)

# Export NDDI bulan agustus
NDDI_export_path = '/content/drive/MyDrive/Bahan_Penelitian/Data_Kekeringan_Final_2019/Sentinel2_NDDI_Agustus_2019.tif'

# Write the clipped raster to a new GeoTIFF file
with rasterio.open(NDDI_export_path, "w", **meta_nddi) as dst:
    dst.write(NDDI_agustus, 1) # Pilih NDDI: , 1 menunjukan hanya export satu band
print("NDDI completed and saved as", NDDI_export_path)

# Export NDDI bulan September
NDDI_export_path = '/content/drive/MyDrive/Bahan_Penelitian/Data_Kekeringan_Final_2019/Sentinel2_NDDI_September_2019.tif'

# Write the clipped raster to a new GeoTIFF file
with rasterio.open(NDDI_export_path, "w", **meta_nddi) as dst:
    dst.write(NDDI_september, 1) # Pilih NDDI: , 1 menunjukan hanya export satu band
print("NDDI completed and saved as", NDDI_export_path)

# Export NDDI bulan Oktober
NDDI_export_path = '/content/drive/MyDrive/Bahan_Penelitian/Data_Kekeringan_Final_2019/Sentinel2_NDDI_Oktober_2019.tif'

# Write the clipped raster to a new GeoTIFF file
with rasterio.open(NDDI_export_path, "w", **meta_nddi) as dst:
    dst.write(NDDI_oktober, 1) # Pilih NDDI: , 1 menunjukan hanya export satu band
print("NDDI completed and saved as", NDDI_export_path)

"""## Pengkelas NDDI menjadi kelas kekeringan
Indeks NDDI yang telah dibuat setiap bulannya akan diguanakan sebagai input data. Namun, karena indeks NDDI tersebut masih berupa continue values atau nilai piksel indeks maka Langkah pertama adalah kita harus mengkelaskan indeks NDDI tersebut terlebih dahulu.

Berdasarkan:
https://iopscience.iop.org/article/10.1088/1755-1315/1109/1/012027/meta

Pembagian kelas kekeringan berdasarkan nilai NDDI:
* lower than -2 = very low == class 0
* -2 to 0.7 = Low == class 1
* 0.7 to 1.25 = Moderate == class 2
* 1.25 to 3 = High == class 3
* more than 3 = Very High == class 4


"""

# Fungsi untuk mereklasifikasi nilai NDDI
def reclassify_nddi(nddi):
    reclassified = np.zeros_like(nddi)  # Array untuk hasil reklasifikasi
    reclassified[nddi < -2] = 0  # Very Low
    reclassified[(nddi >= -2) & (nddi < 0.7)] = 1  # Low
    reclassified[(nddi >= 0.7) & (nddi < 1.25)] = 2  # Moderate
    reclassified[(nddi >= 1.25) & (nddi < 3)] = 3  # High
    reclassified[nddi >= 3] = 4  # Very High
    return reclassified

# Menerapkan fungsi reklasifikasi kedalam setiap bulan NDDI
rec_NDDI_juli = reclassify_nddi(NDDI_juli)
rec_NDDI_agustus = reclassify_nddi(NDDI_agustus)
rec_NDDI_september = reclassify_nddi(NDDI_september)
rec_NDDI_oktober = reclassify_nddi(NDDI_oktober)

# Cek hasil reklasifikasi
print(np.unique(rec_NDDI_juli))

# Reklasifikasi dan visualisasi untuk setiap bulan
rec_NDDI = [rec_NDDI_juli, rec_NDDI_agustus, rec_NDDI_september,rec_NDDI_oktober ]
titles = ['NDDI Bulan Juli', 'NDDI Bulan Agustus', 'NDDI Bulan September', 'NDDI Bulan Oktober']

import matplotlib.colors as mcolors

# Kolormap diskrit untuk 5 kelas
classes = ['Very Low', 'Low', 'Moderate', 'High', 'Very High']
cmap = mcolors.ListedColormap(['#064506','#90EE90','yellow','orange','red'])
bounds = [0, 1, 2, 3, 4, 5]
norm = mcolors.BoundaryNorm(bounds, cmap.N)

# Visualisasi
for i, data in enumerate(rec_NDDI):
    plt.figure(figsize=(6, 6))
    plt.imshow(data, cmap=cmap, norm=norm)
    cbar = plt.colorbar(shrink=0.7, ticks=[0, 1, 2, 3, 4])
    cbar.ax.set_yticklabels(classes)  # Label kelas pada colorbar
    cbar.set_label('NDDI Classification')
    plt.title(f'Reclassified {titles[i]}')
    plt.axis('off')  # Matikan axis
    plt.tight_layout()
    plt.show()

# Export NDDI Reklasifikasi bulan juli
NDDI_rec_export_path = '/content/drive/MyDrive/Bahan_Penelitian/Data_Kekeringan_Final_2019/Data/Sentinel2_NDDI_Reklasifikasi_Juli_2019.tif'

# Write the clipped raster to a new GeoTIFF file
with rasterio.open(NDDI_rec_export_path, "w", **meta_nddi) as dst:
    dst.write(rec_NDDI_juli, 1) # Pilih NDDI Reklasifikasi: , 1 menunjukan hanya export satu band
print("NDDI completed and saved as", NDDI_rec_export_path)

# Export NDDI Reklasifikasi bulan Agustus
NDDI_rec_export_path = '/content/drive/MyDrive/Bahan_Penelitian/Data_Kekeringan_Final_2019/Data/Sentinel2_NDDI_Reklasifikasi_Agustus_2019.tif'

# Write the clipped raster to a new GeoTIFF file
with rasterio.open(NDDI_rec_export_path, "w", **meta_nddi) as dst:
    dst.write(rec_NDDI_agustus, 1) # Pilih NDDI Reklasifikasi: , 1 menunjukan hanya export satu band
print("NDDI completed and saved as", NDDI_rec_export_path)

# Export NDDI Reklasifikasi bulan September
NDDI_rec_export_path = '/content/drive/MyDrive/Bahan_Penelitian/Data_Kekeringan_Final_2019/Data/Sentinel2_NDDI_Reklasifikasi_September_2019.tif'

# Write the clipped raster to a new GeoTIFF file
with rasterio.open(NDDI_rec_export_path, "w", **meta_nddi) as dst:
    dst.write(rec_NDDI_september, 1) # Pilih NDDI Reklasifikasi: , 1 menunjukan hanya export satu band
print("NDDI completed and saved as", NDDI_rec_export_path)

# Export NDDI Reklasifikasi bulan Oktober
NDDI_rec_export_path = '/content/drive/MyDrive/Bahan_Penelitian/Data_Kekeringan_Final_2019/Data/Sentinel2_NDDI_Reklasifikasi_Oktober_2019.tif'

# Write the clipped raster to a new GeoTIFF file
with rasterio.open(NDDI_rec_export_path, "w", **meta_nddi) as dst:
    dst.write(rec_NDDI_september, 1) # Pilih NDDI Reklasifikasi: , 1 menunjukan hanya export satu band
print("NDDI completed and saved as", NDDI_rec_export_path)

"""## Pembuatan independent variables input features dari Sentinel-2

Pada part ini, kita akan menambahkan beberapa spektral indeks kedalam band original Sentinel-2 kita.
Spektral indeks yang akan kita kalkuasi adalah:
* NDVI (Normalized Difference Vegetation Index) = (NIR-RED)/(NIR+RED)
* NDWI (Normalized Difference Vegetation Index) = (NIR-SWIR1)/(NIR+SWIR1)
* NDSI (Normalized Difference Soil Index) = (SWIR1-NIR)/(SWIR1+NIR)

"""

# Membuat function untuk membuat spectral indices
def calculate_spectral_indices(S2_image_all):
    # Extract bands dari S2_image_all
    red = S2_image_all[:, :, 2]    # B4
    nir = S2_image_all[:, :, 3]    # B8
    swir1 = S2_image_all[:, :, 4]  # B11

    # NDVI: (NIR - Red) / (NIR + Red)
    NDVI = (nir - red) / (nir + red)

    # NDWI : (NIR-SWIR1)/(NIR+SWIR1)
    NDWI = (nir - swir1) / (nir + swir1)

    # NDSI : (SWIR1-NIR)/(SWIR1+NIR)
    NDSI = (swir1 - nir) / (swir1 + nir)

    # Stack spectral indices
    spectral_indices = np.stack([NDVI, NDWI, NDSI], axis=-1)

    # Concatenate atau menggabungkan original bands dengan the spectral indices
    S2_image_with_indices = np.concatenate((S2_image_all, spectral_indices), axis=-1)

    return S2_image_with_indices

# Membuat input data dengan 10 bands: 6 original bands, 1 band slope dan 3 spectral indices
S2_with_indices_juli = calculate_spectral_indices(S2_juli_all)
print(S2_with_indices_juli.shape)
# blue, green, red, nir, swir1, swir2, Slope, NDVI, NDWI, NDSI

S2_with_indices_agustus = calculate_spectral_indices(S2_agustus_all)
print(S2_with_indices_agustus.shape)

S2_with_indices_september = calculate_spectral_indices(S2_september_all)
print(S2_with_indices_september.shape)

S2_with_indices_oktober = calculate_spectral_indices(S2_oktober_all)
print(S2_with_indices_oktober.shape)

# Membuat Loop untuk plotting semua spectral index sekaligus:

# List nama spectral index
spectral_index_names = ['LST', 'TCI', 'elevation', 'slope', 'Precipitation', 'VCI', 'VHI', 'NDVI', 'NDWI', 'NDSI']

# Start index untuk VCI adalah index ke 8
start_index = 6

# Loop untuk semua spectral index dan plot semuanya
for i, index_name in enumerate(spectral_index_names):
    plt.figure(figsize=(6, 6))
    plt.imshow(S2_with_indices_september[:, :, start_index + i], cmap='RdYlGn')
    plt.colorbar(label=index_name, shrink=0.5)
    plt.title(f'Sentinel-2 Juli {index_name}')
    plt.show()

# Menyimpan data S2 dengan indeks kedalam google drive kita
S2_dataset_juli.meta

# langkah pertama adalah untuk mendapatkan metadatq dari original dataset
meta = S2_dataset_juli.meta.copy()

# Kemudian memperbaharui meta data karena kita memiliki 11 bands
meta.update({
    "count": 16,  # 6 orignal bands + slope + elevation + 6 spectral index
    "dtype": 'float32',  # Set the data type to float32
    "driver": 'GTiff'  # Save as GeoTIFF
})

meta

# Mendefiniskan deskripsi nama bands (original bands + spectral indices)
band_descriptions = ['B2', 'B3', 'B4', 'B8', 'B11', 'B12', 'LST', 'TCI', 'elevation', 'slope', 'Precipitation', 'VCI', 'VHI', 'NDVI', 'NDWI', 'NDSI']

# menyimpan bulan Juli
# Tempat untuk menyimpan file tif.
output_file_path_S2New = '/content/drive/MyDrive/Bahan_Penelitian/Data_Kekeringan_Final_2019/Data/S2_with_Spectral_Indices_Juli_2019.tif'

# Export Sentinel-2 dengan sepctral indices
with rasterio.open(output_file_path_S2New, 'w', **meta) as dst:
    for i in range(16):
        dst.write(S2_with_indices_juli[:, :, i], i + 1)  # Write each band

        # Menambahkan deskripsi band names untuk setiap bands
        dst.set_band_description(i + 1, band_descriptions[i])

# menyimpan bulan Agustus
# Tempat untuk menyimpan file tif.
output_file_path_S2New = '/content/drive/MyDrive/Bahan_Penelitian/Data_Kekeringan_Final_2019/Data/S2_with_Spectral_Indices_Agustus_2019.tif'

# Export Sentinel-2 dengan sepctral indices
with rasterio.open(output_file_path_S2New, 'w', **meta) as dst:
    for i in range(16):
        dst.write(S2_with_indices_agustus[:, :, i], i + 1)  # Write each band

        # Menambahkan deskripsi band names untuk setiap bands
        dst.set_band_description(i + 1, band_descriptions[i])

# menyimpan bulan September
# Tempat untuk menyimpan file tif.
output_file_path_S2New = '/content/drive/MyDrive/Bahan_Penelitian/Data_Kekeringan_Final_2019/Data/S2_with_Spectral_Indices_September_2019.tif'

# Export Sentinel-2 dengan sepctral indices
with rasterio.open(output_file_path_S2New, 'w', **meta) as dst:
    for i in range(16):
        dst.write(S2_with_indices_september[:, :, i], i + 1)  # Write each band

        # Menambahkan deskripsi band names untuk setiap bands
        dst.set_band_description(i + 1, band_descriptions[i])

# menyimpan bulan Oktober
# Tempat untuk menyimpan file tif.
output_file_path_S2New = '/content/drive/MyDrive/Bahan_Penelitian/Data_Kekeringan_Final_2019/Data/S2_with_Spectral_Indices_Oktober_2019.tif'

# Export Sentinel-2 dengan sepctral indices
with rasterio.open(output_file_path_S2New, 'w', **meta) as dst:
    for i in range(16):
        dst.write(S2_with_indices_oktober[:, :, i], i + 1)  # Write each band

        # Menambahkan deskripsi band names untuk setiap bands
        dst.set_band_description(i + 1, band_descriptions[i])

"""## Persiapan Input Data Untuk XGBoost training process

* Pada part ini kita akan mencoba mempersiapkan input data untuk training XBoost.

* Input data training akan berasal dari ketiga bulan yang telah kita proses: bulan juli, agustus, dan september.

* Kita akan memilih 15000 pixels input data secara random setiap bulan. total terdapat 45000 input pixels untuk training.

* Input features adalah Sentinel2 bands + slope + 3 spektral index
* Target data adalah hasil klasifikasi kekeringan NDDI

"""

!pip install scikit-learn==1.3.1

# Import Library yang dibutuhkan
import rasterio
import numpy as np
import matplotlib.pyplot as plt

# Membuka Input features dan target data (Reclass NDDI)

# Membuka input features 14 bands
S2_dataset_juli = rasterio.open('/content/drive/MyDrive/Bahan_Penelitian/Data_Kekeringan_Final_2019/Data/S2_with_Spectral_Indices_Juli_2019.tif')
S2_dataset_agustus = rasterio.open('/content/drive/MyDrive/Bahan_Penelitian/Data_Kekeringan_Final_2019/Data/S2_with_Spectral_Indices_Agustus_2019.tif')
S2_dataset_september = rasterio.open('/content/drive/MyDrive/Bahan_Penelitian/Data_Kekeringan_Final_2019/Data/S2_with_Spectral_Indices_September_2019.tif')
S2_dataset_oktober = rasterio.open('/content/drive/MyDrive/Bahan_Penelitian/Data_Kekeringan_Final_2019/Data/S2_with_Spectral_Indices_Oktober_2019.tif')

S2_juli = S2_dataset_juli.read()
S2_juli = S2_juli.transpose(1, 2, 0)

S2_agustus = S2_dataset_agustus.read()
S2_agustus = S2_agustus.transpose(1, 2, 0)

S2_september = S2_dataset_september.read()
S2_september = S2_september.transpose(1, 2, 0)

S2_oktober = S2_dataset_oktober.read()
S2_oktober = S2_oktober.transpose(1, 2, 0)
S2_oktober.shape

# Normalisasi nilai value setiap band menggunakan standard scaler
from sklearn.preprocessing import StandardScaler
import numpy as np

def normalize_bands_standard(rs_image):
    # menginisiasi empty array
    normalized_image = np.zeros_like(rs_image, dtype=np.float32)

    # menambahkan fungsi standardscaler
    scaler = StandardScaler()

    # Normalize setiap band menggunakan standardscaler
    for band in range(rs_image.shape[2]):
        band_data = rs_image[:, :, band]

        # Flatten band kedalam 1D array
        band_data_flattened = band_data.flatten().reshape(-1, 1)

        # apply untuk setiap band
        scaled_band = scaler.fit_transform(band_data_flattened)

        # Reshape kembali ke shape awal
        normalized_image[:, :, band] = scaled_band.reshape(band_data.shape)

    return normalized_image

# Menerapkan fungsi standardscaler
S2_juli = normalize_bands_standard(S2_juli)
S2_agustus = normalize_bands_standard(S2_agustus)
S2_september = normalize_bands_standard(S2_september)
S2_oktober = normalize_bands_standard(S2_oktober)

# Check hasil normalisasi
np.nanmin(S2_agustus)

# Membuka target data (Reclass NDDI)

tar_NDDI_juli = rasterio.open('/content/drive/MyDrive/Bahan_Penelitian/Data_Kekeringan_Final_2019/Data/Sentinel2_NDDI_Reklasifikasi_Juli_2019.tif')
tar_NDDI_agustus = rasterio.open('/content/drive/MyDrive/Bahan_Penelitian/Data_Kekeringan_Final_2019/Data/Sentinel2_NDDI_Reklasifikasi_Agustus_2019.tif')
tar_NDDI_september = rasterio.open('/content/drive/MyDrive/Bahan_Penelitian/Data_Kekeringan_Final_2019/Data/Sentinel2_NDDI_Reklasifikasi_September_2019.tif')
tar_NDDI_oktober = rasterio.open('/content/drive/MyDrive/Bahan_Penelitian/Data_Kekeringan_Final_2019/Data/Sentinel2_NDDI_Reklasifikasi_Oktober_2019.tif')

tar_NDDI_juli = tar_NDDI_juli.read()
tar_NDDI_juli = tar_NDDI_juli.transpose(1, 2, 0)

tar_NDDI_agustus = tar_NDDI_agustus.read()
tar_NDDI_agustus = tar_NDDI_agustus.transpose(1, 2, 0)

tar_NDDI_september = tar_NDDI_september.read()
tar_NDDI_september = tar_NDDI_september.transpose(1, 2, 0)

tar_NDDI_oktober = tar_NDDI_oktober.read()
tar_NDDI_oktober = tar_NDDI_oktober.transpose(1, 2, 0)

tar_NDDI_oktober.shape

"""#### Membuat fungsi untuk membuat training data dari input Sentinel-2 dan traget data"""

import numpy as np
import random
from collections import Counter

def create_training_data(S2_juli, S2_agustus, S2_september, S2_oktober, tar_NDDI_juli, tar_NDDI_agustus, tar_NDDI_september, tar_NDDI_oktober, num_samples_per_month=10000):

    def sample_pixels(S2_data, target_data, num_samples):
        H, W, B = S2_data.shape
        pixels = [(i, j) for i in range(H) for j in range(W)]

        # Mendapatkan target class
        labels = np.array([target_data[i, j, 0] for i, j in pixels])

        # mendapatkan total setiap kelas
        class_counts = Counter(labels)

        # mendapatkan unique value setiap kelas
        unique_classes = list(class_counts.keys())

        sampled_pixels = []
        sampled_labels = []

        # Untuk setiap kelas, sampel piksel proporsional dengan num_samples
        for c in unique_classes:
            class_pixels = [pixels[i] for i in range(len(pixels)) if labels[i] == c]
            num_class_samples = min(len(class_pixels), num_samples // len(unique_classes))
            sampled_class_pixels = random.sample(class_pixels, num_class_samples)

            # Tambahkan piksel sampel dan label yang sesuai
            sampled_pixels.extend(sampled_class_pixels)
            sampled_labels.extend([c] * num_class_samples)

        # Ekstrak fitur dan label berdasarkan piksel sampel
        X = np.array([S2_data[i, j, :] for i, j in sampled_pixels])
        y = np.array(sampled_labels)

        return X, y

    # Sample from July data
    X_juli, y_juli = sample_pixels(S2_juli, tar_NDDI_juli, num_samples_per_month)

    # Sample from August data
    X_agustus, y_agustus = sample_pixels(S2_agustus, tar_NDDI_agustus, num_samples_per_month)

    # Sample from September data
    X_september, y_september = sample_pixels(S2_september, tar_NDDI_september, num_samples_per_month)

    # Sample from Oktober data
    X_oktober, y_oktober = sample_pixels(S2_oktober, tar_NDDI_oktober, num_samples_per_month)

    # Combine semua samples
    X_train = np.vstack((X_juli, X_agustus, X_september, X_oktober))
    y_train = np.hstack((y_juli, y_agustus, y_september, y_oktober))

    return X_train, y_train

# Menerapkan fungsi yang telah dibuat
features, labels = create_training_data(S2_juli, S2_agustus, S2_september, S2_oktober, tar_NDDI_juli, tar_NDDI_agustus, tar_NDDI_september, tar_NDDI_oktober, num_samples_per_month=10000)

print("X_train shape:", features.shape)
print("y_train shape:", labels.shape)

# menghitung total samples pada setiap kelas
unique_values, counts = np.unique(labels, return_counts=True)

# Print
for value, count in zip(unique_values, counts):
    print(f"Class {value}: {count} samples")

from sklearn.model_selection import train_test_split

# X_train adalah features untuk training
# X_test aladah features untuk testing
#y_train adalah target atau label training
# y_test adalah traget atau label untuk testing

# Split data: 80% for training and 20% for testing
X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, stratify=labels, random_state=42)
print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)

"""## XGBoost Training Process and Evaluation Assessment
Pada part ini kita akan melakukan training XGboost menggunakan gridsearch cv untuk mencari parameter terbaik.
"""

# Import XGBoost classifier dari library xgboost
from xgboost import XGBClassifier
from sklearn.model_selection import GridSearchCV

# Cross Validation mengambil sebagian data training secara random yang nantinya akan dijadikan validasi untuk menghitung akurasi / performa model selama pelatihan

import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

# Prediksi data testing
y_pred_grid = best_xgb.predict(X_test)

def evaluate_classification(y_true, y_pred):
    # Perhitungan Overall Accuracy
    OA = accuracy_score(y_true, y_pred)
    print(f"Overall Accuracy: {OA:.4f}")

    # Classification report
    class_names = ['No Drought', 'Mild Drought', 'Moderate Drought', 'Severe Drought', 'Extreme Drought']
    report = classification_report(y_true, y_pred, target_names=class_names, digits=4, output_dict=True)

    # Data untuk heatmap classification report
    metrics = ['precision', 'recall', 'f1-score']
    labels = class_names + ['accuracy', 'macro avg', 'weighted avg']
    report_data = []

    for label in class_names:
        row = []
        for metric in metrics:
            row.append(report[label][metric])
        report_data.append(row)

    # Accuracy, macro avg, dan weighted avg
    accuracy_row = [np.nan, np.nan, report['accuracy']]
    report_data.append(accuracy_row)

    for avg_type in ['macro avg', 'weighted avg']:
        row = []
        for metric in metrics:
            row.append(report[avg_type][metric])
        report_data.append(row)

    # Visualisasi
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 12))

    # Classification Report Heatmap
    sns.heatmap(report_data, annot=True, fmt='.4f', cmap='coolwarm',
                xticklabels=metrics, yticklabels=labels, ax=ax1)
    ax1.set_title('Classification Report', fontsize=14)
    ax1.set_xlabel('Metrics')
    ax1.set_ylabel('Classes')

    # Confusion Matrix Heatmap
    cm = confusion_matrix(y_true, y_pred)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,
                xticklabels=class_names, yticklabels=class_names, ax=ax2)
    ax2.set_xlabel('Predicted Label')
    ax2.set_ylabel('True Label')
    ax2.set_title('Confusion Matrix', fontsize=14)

    plt.tight_layout()
    plt.show()

# XGBoost Classifier awal
init_xgb_model = XGBClassifier(random_state=42)

# Mendeifiniskan list beberapa parameter yang akan digunakan untuk hyperparameter tuning
param_grid = {
    'n_estimators': [100, 300, 500],
    'max_depth': [3, 6, 9],
    'eta': [0.1, 0.3, 0.5],
    'gamma': [0, 0.1, 0.2],
    'subsample': [0.8, 1.0],
    'colsample_bytree': [0.8, 1.0],
}

# GridSearchCV dengan 5-fold cross-validation
grid_search = GridSearchCV(init_xgb_model, param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=5)

import time

# Start the timer
start_time = time.time()

# Train XGBoost model dengan grid_search
grid_search.fit(X_train, y_train)

# End the timer
end_time = time.time()

# Calculate and print the time taken
elapsed_time = end_time - start_time
print(f"Waktu yang dibutuhkan untuk running adalah: {elapsed_time:.3f} seconds")

# Print the best parameters
print("Best parameters adalah:", grid_search.best_params_)
print("Best cross-validation accuracy:", grid_search.best_score_)

# Evaluation assessment
# Menggunakan scikit-learn library untuk menghitung overall accuacy, classification report, dan confusion metrix
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

#Menerapkan best parameter xgb
best_xgb = grid_search.best_estimator_

# Menerapkan xgb_model_default untuk memprediksi kelas dari tetsing dataset
y_pred_grid = best_xgb.predict(X_test)

# Membuat feature importance

from xgboost import plot_importance
import matplotlib.pyplot as plt

# Band list
band_descriptions = ['B2', 'B3', 'B4', 'B8', 'B11', 'B12', 'LST', 'TCI', 'elevation', 'slope', 'Precipitation', 'VCI', 'VHI', 'NDVI', 'NDWI', 'NDSI']

# Set band list sebagai nama features
best_xgb.get_booster().feature_names = band_descriptions

# Plot feature important,
# https://xgboost.readthedocs.io/en/stable/python/python_api.html#xgboost.plot_importance
plt.figure(figsize=(10, 8))
plot_importance(best_xgb, importance_type='weight') # Bisa mengganti importance typenya, silahkan cek di link api diatas
plt.title("Feature Importance in XGBoost 2019")
plt.show()

import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

def evaluate_classification(y_true, y_pred):
    # Perhitungan overall accuracy
    OA = accuracy_score(y_true, y_pred)
    print(f"Overall Accuracy: {OA:.4f}")

    # Menghitung classification report dan mengubahnya ke dalam bentuk dictionary
    class_names = ['No Drought', 'Mild Drought', 'Moderate Drought', 'Severe Drought', 'Extreme Drought']
    report = classification_report(y_true, y_pred, target_names=class_names, digits=4, output_dict=True)

    # Membuat data untuk heatmap classification report
    metrics = ['precision', 'recall', 'f1-score']
    labels = class_names + ['accuracy', 'macro avg', 'weighted avg']
    report_data = []

    # Data untuk kelas individual
    for label in class_names:
        row = []
        for metric in metrics:
            row.append(report[label][metric])
        report_data.append(row)

    # Data untuk accuracy
    accuracy_row = [np.nan, np.nan, report['accuracy']]
    report_data.append(accuracy_row)

    # Data untuk macro avg dan weighted avg
    for avg_type in ['macro avg', 'weighted avg']:
        row = []
        for metric in metrics:
            row.append(report[avg_type][metric])
        report_data.append(row)

    # Membuat subplot dengan 2 gambar (vertikal)
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 12))  # 2 rows, 1 column

    # Plot heatmap untuk classification report
    sns.heatmap(report_data, annot=True, fmt='.4f', cmap='coolwarm',
                xticklabels=metrics, yticklabels=labels, ax=ax1)
    ax1.set_title('Classification Report 2019', fontsize=14)
    ax1.set_xlabel('Metrics')
    ax1.set_ylabel('Classes')

    # Plot confusion matrix
    cm = confusion_matrix(y_true, y_pred)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,
                xticklabels=class_names, yticklabels=class_names, ax=ax2)
    ax2.set_xlabel('Predicted Label')
    ax2.set_ylabel('True Label')
    ax2.set_title('Confusion Matrix 2019', fontsize=14)

    plt.tight_layout()
    plt.show()

# # Membuat evaluation function untuk mempermudah kedepannya
# def evaluate_classification(y_true, y_pred):
#     # Perhitungan overall accuracy
#     OA = accuracy_score(y_true, y_pred)

#     # Print Overall Accuracy
#     print(f"Overall Accuracy: {OA:.4f}") # .4f itu untuk decimal number belakang koma

#     # Menghitung classification report: precision, recall, f1-score
#     report = classification_report(y_true, y_pred, digits=4)
#     print(report)

#     # Menghitung confusion matrix
#     class_names = ['Very Low', 'Low', 'Moderate', 'High', 'Very High']
#     cm = confusion_matrix(y_true, y_pred)

#     # Visualisasi confusion matrix menggunakan seaborn heatmap
#     plt.figure(figsize=(8,6))
#     sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,
#                 xticklabels=class_names, yticklabels=class_names)
#     plt.xlabel('Predicted Label')
#     plt.ylabel('True Label')
#     plt.title('Confusion Matrix 2019', fontsize=14)
#     plt.show()

# Menerapkan function evaluation assessment dengan data yang sebenarnya atau y_test dan data hasil prediksi
evaluate_classification(y_test, y_pred_grid)

import joblib

# Save the model
joblib.dump(best_xgb, '/content/drive/MyDrive/Bahan_Penelitian/Data_Kekeringan_Final_2019/Data/best_xgb_kekeringan_model_2019.pkl')



"""## Membuat Peta Kekeringan Berdasarkan XGBoost Trained Model
Pada part ini, kita akan menghasilkan peta penutup lahan menggunakan model XGboost yang telah dilatih. Kita akan menerapkannya pada setiap bulan.
"""

# import AOi kita menggunakan geopandas
import geopandas as gpd

AOI = gpd.read_file('/content/drive/MyDrive/Bahan_Penelitian/Sawah Indramayu 2019/sawah_im_19_gcs.shp')

# Apply model untuk mendapatkan peta Kekekringan keseluruhan citra Sentinel 2A
def classify_raster(raster, model):
    raster_data = raster.reshape(-1, raster.shape[2])  # Reshape to (pixels, bands)
    mask = np.isnan(raster_data).any(axis=1)  # Exclude NaN pixels
    classified = np.full(raster_data.shape[0], np.nan)
    classified[~mask] = model.predict(raster_data[~mask])
    return classified.reshape((raster.shape[0], raster.shape[1]))

# terapkan function classify_raster
classified_map_juli = classify_raster(S2_juli, best_xgb)

classified_map_agustus = classify_raster(S2_agustus, best_xgb)

classified_map_september = classify_raster(S2_september, best_xgb)

classified_map_oktober = classify_raster(S2_oktober, best_xgb)

classified_map_juli.shape

"""### Visualisasi Peta Kekeringan"""

import matplotlib.patches as mpatches
import matplotlib.colors as mcolors
from matplotlib.colors import ListedColormap

# Mendefinisikan Legend dan warna untuk setiap kelas
legend_labels = ['Very Low', 'Low', 'Moderate', 'High', 'Very High']
legend_colors = ['#064506','#90EE90', 'yellow', 'orange', 'red']

# Membuat figure untuk dua subplot: 1 untuk Sentinel-2 dan 2. untuk  hasil klasifikasi XGBoost
fig, ax = plt.subplots(1, 4, figsize=(18, 8))

# Klasifikasi XGBoost
# Mendefinisikan colormap
cmap = ListedColormap(legend_colors)

# Display hasil klasifikasi XGBoost
im = ax[0].imshow(classified_map_juli, cmap=cmap, extent=[AOI.total_bounds[0], AOI.total_bounds[2],AOI.total_bounds[1], AOI.total_bounds[3]])
ax[0].set_title('Peta Klasifikasi Kekeringan XGBoost Juli')

# Display hasil klasifikasi XGBoost
im = ax[1].imshow(classified_map_agustus, cmap=cmap, extent=[AOI.total_bounds[0], AOI.total_bounds[2],AOI.total_bounds[1], AOI.total_bounds[3]])
ax[1].set_title('Peta Klasifikasi Kekeringan XGBoost Agustus')

# Display hasil klasifikasi XGBoost
im = ax[2].imshow(classified_map_september, cmap=cmap, extent=[AOI.total_bounds[0], AOI.total_bounds[2],AOI.total_bounds[1], AOI.total_bounds[3]])
ax[2].set_title('Peta Klasifikasi Kekeringan XGBoost September')

# Display hasil klasifikasi XGBoost
im = ax[3].imshow(classified_map_oktober, cmap=cmap, extent=[AOI.total_bounds[0], AOI.total_bounds[2],AOI.total_bounds[1], AOI.total_bounds[3]])
ax[3].set_title('Peta Klasifikasi Kekeringan XGBoost Oktober')

# Membuat legend
legend_handles = [mpatches.Patch(color=legend_colors[i], label=legend_labels[i]) for i in range(len(legend_labels))]
# menambahkan legend kedalam plot
ax[0].legend(handles=legend_handles, loc='upper left', title="Kelas Kekeringan", fontsize='x-small', title_fontsize='medium', edgecolor="black", fancybox=True)
ax[1].legend(handles=legend_handles, loc='upper left', title="Kelas Kekeringan", fontsize='x-small', title_fontsize='medium', edgecolor="black", fancybox=True)
ax[2].legend(handles=legend_handles, loc='upper left', title="Kelas Kekeringan", fontsize='x-small', title_fontsize='medium', edgecolor="black", fancybox=True)
ax[3].legend(handles=legend_handles, loc='upper left', title="Kelas Kekeringan", fontsize='x-small', title_fontsize='medium', edgecolor="black", fancybox=True)

plt.tight_layout()
# plt.savefig('/content/drive/MyDrive/Geosoftware_Kekeringan_NDDI/Peta_Kekeringan_Setiap_Bulan.jpeg', dpi=600)
plt.show()

"""### Export raster hasil klasifikasi"""

import rasterio
from rasterio.transform import from_origin

def export_classified_map(classified_map, reference_raster, output_path):
    # Mendapatkan metadata dari data Sentinel-2
    meta = reference_raster.meta.copy()

    # Update the metadata
    meta.update({
        "driver": "GTiff",
        "dtype": 'int32',  # Untuk integer class (0,1,2,3,4)
        "count": 1,        # Hanya satu band
        "compress": "lzw"  # file compression
    })

    with rasterio.open(output_path, 'w', **meta) as dst:
        dst.write(classified_map.astype('int32'), 1)

# Menerapkan fungsi yang telah dibuat untuk setiap bulan

# Juli
output_tif_path_juli = '/content/drive/MyDrive/Bahan_Penelitian/Data_Kekeringan_Final_2019/Drought Map/Hasil_Klasifikasi_Kekeringan_Juli_2019.tif'
export_classified_map(classified_map_juli, S2_dataset_juli, output_tif_path_juli)

# Agustus
output_tif_path_agustus = '/content/drive/MyDrive/Bahan_Penelitian/Data_Kekeringan_Final_2019/Drought Map/Hasil_Klasifikasi_Kekeringan_Agustus_2019.tif'
export_classified_map(classified_map_agustus, S2_dataset_juli, output_tif_path_agustus)

# September
output_tif_path_september = '/content/drive/MyDrive/Bahan_Penelitian/Data_Kekeringan_Final_2019/Drought Map/Hasil_Klasifikasi_Kekeringan_September_2019.tif'
export_classified_map(classified_map_september, S2_dataset_juli, output_tif_path_september)

# Oktober
output_tif_path_oktober = '/content/drive/MyDrive/Bahan_Penelitian/Data_Kekeringan_Final_2019/Drought Map/Hasil_Klasifikasi_Kekeringan_Oktober_2019.tif'
export_classified_map(classified_map_oktober, S2_dataset_juli, output_tif_path_oktober)

"""### Analisis luasan kekeringan"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# Tentukan label, kelas, dan ukuran piksel dalam hektar
labels = ['No Drought', 'Mild Drought', 'Moderate Drought', 'Severe Drought', 'Extreme Drought']
classes = [0, 1, 2, 3, 4]
pixel_area_ha = 0.01  # 10x10 m sentinel-2

# Fungsi untuk menghitung luas kelas
def calculate_class_areas(classified_map, classes, pixel_area_ha):
    areas = {}
    total_area = 0
    for cls in classes:
        pixel_count = np.sum(classified_map == cls)
        area = pixel_count * pixel_area_ha
        areas[cls] = area
        total_area += area
    return areas, total_area

# Hitung area untuk setiap bulan
areas_juli, total_area_juli = calculate_class_areas(classified_map_juli, classes, pixel_area_ha)
areas_agustus, total_area_agustus = calculate_class_areas(classified_map_agustus, classes, pixel_area_ha)
areas_september, total_area_september = calculate_class_areas(classified_map_september, classes, pixel_area_ha)
areas_oktober, total_area_oktober = calculate_class_areas(classified_map_oktober, classes, pixel_area_ha)

# Buat DataFrame dengan struktur yang sesuai untuk stacked bar chart
area_df = pd.DataFrame({
    "Month": ["July", "August", "September", "October"],
    "No Drought": [areas_juli[0], areas_agustus[0], areas_september[0], areas_oktober[0]],
    "Mild Drought": [areas_juli[1], areas_agustus[1], areas_september[1], areas_oktober[1]],
    "Moderate Drought": [areas_juli[2], areas_agustus[2], areas_september[2], areas_oktober[2]],
    "Severe Drought": [areas_juli[3], areas_agustus[3], areas_september[3], areas_oktober[3]],
    "Extreme Drought": [areas_juli[4], areas_agustus[4], areas_september[4], areas_oktober[4]]
})

# Set warna untuk setiap tingkat kekeringan
colors = ['#2ecc71',  # Hijau
          '#98fb98',  # Hijau Muda
          '#f1c40f',  # Kuning
          '#e67e22',  # Oranye
          '#e74c3c']  # Merah

# Buat stacked bar chart
plt.figure(figsize=(12, 8))

# Plot batang bertumpuk
bottom = np.zeros(len(area_df["Month"]))
for i, col in enumerate(labels):
    plt.bar(area_df["Month"], area_df[col], bottom=bottom,
            label=col, color=colors[i])
    bottom += area_df[col]

# Kustomisasi plot
plt.xlabel('Month', fontsize=12, fontweight='bold')
plt.ylabel('Area (Ha)', fontsize=12, fontweight='bold')
plt.title('Distribution of Drought Severity 2019',
          fontsize=14, fontweight='bold', pad=20)

# Atur legend
plt.legend(title='Drought Severity',
          bbox_to_anchor=(1.05, 1),
          loc='upper left')

# Tambahkan grid
plt.grid(axis='y', linestyle='--', alpha=0.3)

# Atur layout agar legend tidak terpotong
plt.tight_layout()

# Tampilkan plot
plt.show()

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# Tentukan label, kelas, dan ukuran piksel dalam hektar
labels = ['Very Low', 'Low', 'Moderate', 'High', 'Very High']
classes = [0, 1, 2, 3, 4]
pixel_area_ha = 0.01  # 10x10 m sentinel-2

# Fungsi untuk menghitung luas kelas
def calculate_class_areas(classified_map, classes, pixel_area_ha):
    areas = {}
    total_area = 0
    for cls in classes:
        # Hitung jumlah piksel untuk setiap kelas
        pixel_count = np.sum(classified_map == cls)
        # Ubah jumlah piksel menjadi luas dalam hektar
        area = pixel_count * pixel_area_ha
        areas[cls] = area
        total_area += area  # Akumulasi total area
    return areas, total_area

# Hitung area untuk setiap bulan
areas_juli, total_area_juli = calculate_class_areas(classified_map_juli, classes, pixel_area_ha)
areas_agustus, total_area_agustus = calculate_class_areas(classified_map_agustus, classes, pixel_area_ha)
areas_september, total_area_september = calculate_class_areas(classified_map_september, classes, pixel_area_ha)
areas_oktober, total_area_oktober = calculate_class_areas(classified_map_oktober, classes, pixel_area_ha)

# Buat DataFrame untuk memudahkan analisis
area_df = pd.DataFrame({
    "Class": labels,
    "Juli": [areas_juli[cls] for cls in classes],
    "Agustus": [areas_agustus[cls] for cls in classes],
    "September": [areas_september[cls] for cls in classes],
    "Oktober": [areas_oktober[cls] for cls in classes]
})

# Print DataFrame
print(area_df)

# Warna untuk setiap kelas kekeringan
colors = ['green', 'lightgreen', 'yellow', 'orange', 'red']

# Plot the data
plt.figure(figsize=(12, 7))

# Indeks untuk sumbu X
x = np.arange(len(area_df.columns[1:]))  # Indeks untuk bulan
bar_width = 0.15  # Lebar batang

# Plot bars untuk setiap tingkat kekeringan
for i, cls in enumerate(classes):
    plt.bar(x + i * bar_width, area_df.iloc[i, 1:], width=bar_width, label=labels[i], color=colors[i])

# Add labels, title, and grid
plt.xticks(x + (len(classes) - 1) * bar_width / 2, area_df.columns[1:])  # Posisi label bulan di tengah grup batang
plt.xlabel('Bulan')
plt.ylabel('Luas Area (Ha)')
plt.title('Distribusi Tingkat Kekeringan per Bulan')
plt.legend(title='Tingkat Kekeringan')
plt.grid(axis='y', linestyle='--', alpha=0.7)

# Show the plot
plt.tight_layout()
plt.show()